{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\adity\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torch\\utils\\_pytree.py:185: FutureWarning: optree is installed but the version is too old to support PyTorch Dynamo in C++ pytree. C++ pytree support is disabled. Please consider upgrading optree using `python3 -m pip install --upgrade 'optree>=0.13.0'`.\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "from sklearn.inspection import permutation_importance\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader, TensorDataset\n",
        "import torch\n",
        "import joblib"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "mI3pJU77WJ-D"
      },
      "outputs": [],
      "source": [
        "# Load dataset\n",
        "df = pd.read_csv('E:\\\\hacktu\\\\preprocessed_under.csv')\n",
        "# df['CreditScore'] = df['CreditScore']\n",
        "\n",
        "# Separate features and target\n",
        "X = df.drop('LoanApproved', axis=1)\n",
        "y = df['LoanApproved']\n",
        "\n",
        "# Split data\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, stratify=y, random_state=9)\n",
        "\n",
        "# Identify categorical and numerical columns\n",
        "cat_cols = X.select_dtypes(include=['object', 'category']).columns.tolist()\n",
        "num_cols = X.select_dtypes(include=['int64', 'float64']).columns.tolist()\n",
        "\n",
        "# Preprocessing pipeline\n",
        "preprocessor = ColumnTransformer(\n",
        "    transformers=[\n",
        "        ('num', Pipeline(steps=[\n",
        "            ('imputer', SimpleImputer(strategy='median')),\n",
        "            ('scaler', StandardScaler())\n",
        "        ]), num_cols),\n",
        "        ('cat', Pipeline(steps=[\n",
        "            ('imputer', SimpleImputer(strategy='most_frequent')),\n",
        "            ('onehot', OneHotEncoder(handle_unknown='ignore'))\n",
        "        ]), cat_cols)\n",
        "    ])\n",
        "\n",
        "\n",
        "# Apply preprocessing\n",
        "X_train_preprocessed = preprocessor.fit_transform(X_train)\n",
        "X_test_preprocessed = preprocessor.transform(X_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e8u1RYvYX71I",
        "outputId": "8d0e549e-8f47-481c-c626-1c61d1e3b4d1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Feature ranking:\n",
            "num__InterestRate             : 0.044\n",
            "num__MonthlyIncome            : 0.041\n",
            "num__NetWorth                 : 0.028\n",
            "num__LoanAmount               : 0.028\n",
            "num__MonthlyLoanPayment       : 0.018\n",
            "num__InterestRate_LoanDuration: 0.005\n",
            "num__AnnualIncome             : 0.004\n",
            "num__TotalIncome              : 0.004\n",
            "num__CreditScore              : 0.004\n",
            "num__MonthlyDebtPayments      : 0.003\n",
            "num__CreditScore_Income       : 0.003\n",
            "num__EducationLevel           : 0.002\n",
            "num__CheckingAccountBalance   : 0.001\n",
            "num__HomeOwnershipStatus      : 0.001\n",
            "num__DebtToIncome_CreditScore : 0.001\n",
            "num__LoanDuration             : 0.001\n",
            "num__LoanPurpose              : 0.000\n",
            "num__DebtToIncomeRatio        : 0.000\n",
            "num__EmploymentStatus         : 0.000\n",
            "num__NumberOfDependents       : 0.000\n",
            "num__SavingsAccountBalance    : 0.000\n",
            "num__JobTenure                : 0.000\n",
            "num__MaritalStatus            : -0.000\n",
            "num__BaseInterestRate         : -0.000\n",
            "num__Experience               : -0.001\n",
            "num__Age                      : -0.001\n"
          ]
        }
      ],
      "source": [
        "# Temporary model for feature analysis\n",
        "rf = RandomForestClassifier(n_estimators=100)\n",
        "rf.fit(X_train_preprocessed, y_train)\n",
        "\n",
        "# Permutation importance\n",
        "result = permutation_importance(\n",
        "    rf, X_test_preprocessed, y_test, n_repeats=10, random_state=42\n",
        ")\n",
        "\n",
        "# Display feature importance\n",
        "feature_names = preprocessor.get_feature_names_out()\n",
        "sorted_idx = result.importances_mean.argsort()[::-1]\n",
        "\n",
        "print(\"Feature ranking:\")\n",
        "for i in sorted_idx:\n",
        "    print(f\"{feature_names[i]:<30}: {result.importances_mean[i]:.3f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o2Gpnqm1YFMm",
        "outputId": "a335c006-a1f8-4d57-b5ce-47e937120904"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.96      0.87      0.91       956\n",
            "           1       0.88      0.97      0.92       956\n",
            "\n",
            "    accuracy                           0.92      1912\n",
            "   macro avg       0.92      0.92      0.92      1912\n",
            "weighted avg       0.92      0.92      0.92      1912\n",
            "\n",
            "[[827 129]\n",
            " [ 30 926]]\n"
          ]
        }
      ],
      "source": [
        "# Convert to PyTorch tensors\n",
        "X_train_tensor = torch.tensor(X_train_preprocessed.tolist(), dtype=torch.float32)\n",
        "y_train_tensor = torch.tensor(y_train.values, dtype=torch.long)\n",
        "X_test_tensor = torch.tensor(X_test_preprocessed.tolist(), dtype=torch.float32)\n",
        "y_test_tensor = torch.tensor(y_test.values, dtype=torch.long)\n",
        "\n",
        "# Create DataLoader\n",
        "train_dataset = TensorDataset(X_train_tensor, y_train_tensor)\n",
        "train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
        "\n",
        "# Define model\n",
        "class MLP(nn.Module):\n",
        "    def __init__(self, input_dim, num_classes):\n",
        "        super(MLP, self).__init__()\n",
        "        self.layers = nn.Sequential(\n",
        "            nn.Linear(input_dim, 128),\n",
        "            nn.BatchNorm1d(128),  # Stabilize training\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(0.5),  # Reduce overfitting\n",
        "            nn.Linear(128, 64),\n",
        "            nn.BatchNorm1d(64),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(0.3),\n",
        "            nn.Linear(64, num_classes)\n",
        "        )\n",
        "        # Custom weight initialization\n",
        "        self._init_weights()\n",
        "\n",
        "    def _init_weights(self):\n",
        "        for m in self.modules():\n",
        "            if isinstance(m, nn.Linear):\n",
        "                nn.init.kaiming_normal_(m.weight, mode='fan_in', nonlinearity='relu')\n",
        "                nn.init.constant_(m.bias, 0)\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.layers(x)\n",
        "\n",
        "# Initialize model\n",
        "input_dim = X_train_preprocessed.shape[1]\n",
        "num_classes = len(y.unique())\n",
        "model = MLP(input_dim, num_classes)\n",
        "\n",
        "# Loss and optimizer\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001, weight_decay=1e-4)  # L2 regularization\n",
        "\n",
        "# Training loop\n",
        "num_epochs = 100\n",
        "for epoch in range(num_epochs):\n",
        "    for inputs, labels in train_loader:\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(inputs)\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "\n",
        "        # Optional: Gradient clipping\n",
        "        torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
        "\n",
        "        optimizer.step()\n",
        "\n",
        "# Evaluation\n",
        "with torch.no_grad():\n",
        "    model.eval()\n",
        "    test_outputs = model(X_test_tensor)\n",
        "    _, predicted = torch.max(test_outputs, 1)\n",
        "    print(classification_report(y_test, predicted.numpy()))\n",
        "    print(confusion_matrix(y_test, predicted.numpy()))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['model.joblib']"
            ]
          },
          "execution_count": 7,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "joblib.dump(model, 'model.joblib')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['loan_approval_preprocessor.joblib']"
            ]
          },
          "execution_count": 6,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "joblib.dump(preprocessor, 'loan_approval_preprocessor.joblib')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def get_user_inputs():\n",
        "    # Define which columns are numeric and which are categorical\n",
        "    numeric_cols = [\n",
        "        'Age', 'AnnualIncome', 'CreditScore', 'Experience', 'LoanAmount',\n",
        "        'LoanDuration', 'MonthlyDebtPayments'\n",
        "         'SavingsAccountBalance', 'CheckingAccountBalance', 'MonthlyIncome', 'JobTenure', 'NetWorth',\n",
        "        'BaseInterestRate', 'InterestRate', 'MonthlyLoanPayment',\n",
        "    ]\n",
        "    cat_cols = ['EmploymentStatus', 'EducationLevel', 'MaritalStatus', 'LoanPurpose', 'HomeOwnerShipStatus']\n",
        "    \n",
        "    user_data = {}\n",
        "    # Collect numeric inputs\n",
        "    for col in numeric_cols:\n",
        "        val = input(f\"Enter numeric value for {col}: \")\n",
        "        try:\n",
        "            user_data[col] = float(val)\n",
        "        except ValueError:\n",
        "            print(f\"Invalid numeric input for {col}.\")\n",
        "            return None\n",
        "    \n",
        "    # Load pre-fitted label encoders for categorical columns\n",
        "    label_encoders = joblib.load('label_encoders.joblib')\n",
        "    \n",
        "    # Process categorical inputs using LabelEncoder(s)\n",
        "    for col in cat_cols:\n",
        "        options = list(label_encoders[col].classes_)\n",
        "        print(f\"Options for {col}: {options}\")\n",
        "        val = input(f\"Enter category for {col}: \")\n",
        "        try:\n",
        "            user_data[col] = int(label_encoders[col].transform([val])[0])\n",
        "        except Exception:\n",
        "            print(f\"Invalid input for {col}.\")\n",
        "            return None\n",
        "    \n",
        "    # ...existing feature engineering code...\n",
        "    user_data['TotalIncome'] = user_data['AnnualIncome'] + user_data['SavingsAccountBalance'] + user_data['CheckingAccountBalance']\n",
        "    user_data['DebtToIncomeRatio'] = user_data['MonthlyDebtPayments'] / (user_data['MonthlyIncome'] + 1e-5)\n",
        "    user_data['CreditScore_Income'] = user_data['CreditScore'] * user_data['AnnualIncome']\n",
        "    user_data['DebtToIncome_CreditScore'] = user_data['DebtToIncomeRatio'] * user_data['CreditScore']\n",
        "    user_data['InterestRate_LoanDuration'] = user_data['InterestRate'] * user_data['LoanDuration']\n",
        "\n",
        "    user_df = pd.DataFrame([user_data])\n",
        "    # Rearrange columns to match training order\n",
        "    list_order = ['Age',\n",
        "    'AnnualIncome',\n",
        "    'CreditScore',\n",
        "    'EmploymentStatus',\n",
        "    'EducationLevel',\n",
        "    'Experience',\n",
        "    'LoanAmount',\n",
        "    'LoanDuration',\n",
        "    'MaritalStatus',\n",
        "    'NumberOfDependents',\n",
        "    'HomeOwnershipStatus',\n",
        "    'MonthlyDebtPayments',\n",
        "    'DebtToIncomeRatio',\n",
        "    'LoanPurpose',\n",
        "    'SavingsAccountBalance',\n",
        "    'CheckingAccountBalance',\n",
        "    'MonthlyIncome',\n",
        "    'JobTenure',\n",
        "    'NetWorth',\n",
        "    'BaseInterestRate',\n",
        "    'InterestRate',\n",
        "    'MonthlyLoanPayment',\n",
        "    'TotalIncome',\n",
        "    'CreditScore_Income',\n",
        "    'DebtToIncome_CreditScore',\n",
        "    'InterestRate_LoanDuration']\n",
        "    user_df = user_df.reindex(columns=list_order)\n",
        "    \n",
        "    # Load preprocessor and apply transformation\n",
        "    preprocessor = joblib.load('loan_approval_preprocessor.joblib')\n",
        "    \n",
        "    # Multiply the CreditScore column by 2 *before* preprocessing\n",
        "    user_df['CreditScore'] *= 2\n",
        "    \n",
        "    user_preprocessed = preprocessor.transform(user_df)\n",
        "\n",
        "    # Convert to PyTorch tensor\n",
        "    user_tensor = torch.tensor(user_preprocessed.tolist(), dtype=torch.float32)\n",
        "    return user_tensor\n",
        "\n",
        "# Example usage:\n",
        "# user_tensor = get_user_inputs()\n",
        "# if user_tensor is not None:\n",
        "#     with torch.no_grad():\n",
        "#         model.eval()\n",
        "#         prediction = model(user_tensor)\n",
        "#         print(prediction)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IXZ-eFGHYNWk",
        "outputId": "94fe47d6-41ba-410a-e271-50d92c561d12"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\adity\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\base.py:376: InconsistentVersionWarning: Trying to unpickle estimator LabelEncoder from version 1.6.1 when using version 1.4.0. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
            "https://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Options for EmploymentStatus: ['employed', 'self-employed', 'unemployed']\n",
            "Options for EducationLevel: ['associate', 'bachelor', 'doctorate', 'high school', 'master']\n",
            "Options for MaritalStatus: ['divorced', 'married', 'single', 'widowed']\n",
            "Options for LoanPurpose: ['auto', 'debt consolidation', 'education', 'home', 'other']\n",
            "Options for HomeOwnershipStatus: ['mortgage', 'other', 'own', 'rent']\n",
            "tensor([[1046.6898, -866.2233]])\n"
          ]
        }
      ],
      "source": [
        "def get_user_inputs():\n",
        "    # Define which columns are numeric and which are categorical\n",
        "    numeric_cols = [\n",
        "        'Age', 'AnnualIncome', 'CreditScore', 'Experience', 'LoanAmount',\n",
        "        'LoanDuration', 'MonthlyDebtPayments',\n",
        "         'SavingsAccountBalance', 'CheckingAccountBalance', 'MonthlyIncome', 'JobTenure', 'NetWorth',\n",
        "        'BaseInterestRate', 'InterestRate', 'MonthlyLoanPayment',\n",
        "    ]\n",
        "    cat_cols = ['EmploymentStatus', 'EducationLevel', 'MaritalStatus', 'LoanPurpose', 'HomeOwnershipStatus']\n",
        "    \n",
        "    user_data = {}\n",
        "    # Collect numeric inputs\n",
        "    for col in numeric_cols:\n",
        "        val = input(f\"Enter numeric value for {col}: \")\n",
        "        try:\n",
        "            user_data[col] = float(val)\n",
        "        except ValueError:\n",
        "            print(f\"Invalid numeric input for {col}.\")\n",
        "            return None\n",
        "    # Increase CreditScore weight for user input (match training)\n",
        "    user_data['CreditScore'] = user_data['CreditScore'] * 2\n",
        "    \n",
        "    # Load pre-fitted label encoders for categorical columns\n",
        "    label_encoders = joblib.load('label_encoders.joblib')\n",
        "    \n",
        "    # Process categorical inputs using LabelEncoder(s)\n",
        "    for col in cat_cols:\n",
        "        options = list(label_encoders[col].classes_)\n",
        "        print(f\"Options for {col}: {options}\")\n",
        "        val = input(f\"Enter category for {col}: \")\n",
        "        try:\n",
        "            user_data[col] = int(label_encoders[col].transform([val])[0])\n",
        "        except Exception:\n",
        "            print(f\"Invalid input for {col}.\")\n",
        "            return None\n",
        "    \n",
        "    # ...existing feature engineering code...\n",
        "    user_data['TotalIncome'] = user_data['AnnualIncome'] + user_data['SavingsAccountBalance'] + user_data['CheckingAccountBalance']\n",
        "    user_data['DebtToIncomeRatio'] = user_data['MonthlyDebtPayments'] / (user_data['MonthlyIncome'] + 1e-5)\n",
        "    user_data['CreditScore_Income'] = user_data['CreditScore'] * user_data['AnnualIncome']\n",
        "    user_data['DebtToIncome_CreditScore'] = user_data['DebtToIncomeRatio'] * user_data['CreditScore']\n",
        "    user_data['InterestRate_LoanDuration'] = user_data['InterestRate'] * user_data['LoanDuration']\n",
        "\n",
        "    user_df = pd.DataFrame([user_data])\n",
        "    # Rearrange columns to match training order\n",
        "    list_order = ['Age',\n",
        "    'AnnualIncome',\n",
        "    'CreditScore',\n",
        "    'EmploymentStatus',\n",
        "    'EducationLevel',\n",
        "    'Experience',\n",
        "    'LoanAmount',\n",
        "    'LoanDuration',\n",
        "    'MaritalStatus',\n",
        "    'NumberOfDependents',\n",
        "    'HomeOwnershipStatus',\n",
        "    'MonthlyDebtPayments',\n",
        "    'DebtToIncomeRatio',\n",
        "    'LoanPurpose',\n",
        "    'SavingsAccountBalance',\n",
        "    'CheckingAccountBalance',\n",
        "    'MonthlyIncome',\n",
        "    'JobTenure',\n",
        "    'NetWorth',\n",
        "    'BaseInterestRate',\n",
        "    'InterestRate',\n",
        "    'MonthlyLoanPayment',\n",
        "    'TotalIncome',\n",
        "    'CreditScore_Income',\n",
        "    'DebtToIncome_CreditScore',\n",
        "    'InterestRate_LoanDuration']\n",
        "    user_df = user_df.reindex(columns=list_order)\n",
        "    \n",
        "    # Load preprocessor and apply transformation\n",
        "    preprocessor = joblib.load('loan_approval_preprocessor.joblib')\n",
        "    user_preprocessed = preprocessor.transform(user_df)\n",
        "    \n",
        "    # Convert to PyTorch tensor\n",
        "    user_tensor = torch.tensor(user_preprocessed.tolist(), dtype=torch.float32)\n",
        "    return user_tensor\n",
        "\n",
        "# Example usage:\n",
        "user_tensor = get_user_inputs()\n",
        "if user_tensor is not None:\n",
        "    with torch.no_grad():\n",
        "        model.eval()\n",
        "        prediction = model(user_tensor)\n",
        "        # Get the predicted target by selecting the index with the highest logit\n",
        "        predicted_class = torch.argmax(prediction, dim=1)\n",
        "        print(\"Predicted class:\", predicted_class.item())\n",
        "        if predicted_class.item() == 0:\n",
        "            print(\"The model predicts that the loan will not be approved.\")\n",
        "        else:\n",
        "            print(\"The model predicts that the loan will be approved.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 50,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Probabilities: 0.0\n",
            "Predicted class: tensor([1, 0], dtype=torch.int32)\n"
          ]
        },
        {
          "ename": "RuntimeError",
          "evalue": "a Tensor with 2 elements cannot be converted to Scalar",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "Cell \u001b[1;32mIn[50], line 7\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mProbabilities:\u001b[39m\u001b[38;5;124m\"\u001b[39m, probabilities[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;241m1\u001b[39m]\u001b[38;5;241m.\u001b[39mitem())  \u001b[38;5;66;03m# Probability of class 1\u001b[39;00m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPredicted class:\u001b[39m\u001b[38;5;124m\"\u001b[39m, predicted_class[\u001b[38;5;241m0\u001b[39m])\n\u001b[1;32m----> 7\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[43mpredicted_class\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mitem\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m      8\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe model predicts that the loan will not be approved.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m      9\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
            "\u001b[1;31mRuntimeError\u001b[0m: a Tensor with 2 elements cannot be converted to Scalar"
          ]
        }
      ],
      "source": [
        "probabilities = torch.sigmoid(prediction)\n",
        "predicted_class = (probabilities > 0.5).int()\n",
        "\n",
        "print(\"Probabilities:\", probabilities[0][1].item())  # Probability of class 1\n",
        "print(\"Predicted class:\", predicted_class[0])\n",
        "\n",
        "if predicted_class[0].item() == 0:\n",
        "    print(\"The model predicts that the loan will not be approved.\")\n",
        "else:\n",
        "    print(\"The model predicts that the loan will be approved.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "metadata": {},
      "outputs": [
        {
          "ename": "RuntimeError",
          "evalue": "a Tensor with 2 elements cannot be converted to Scalar",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "Cell \u001b[1;32mIn[46], line 6\u001b[0m\n\u001b[0;32m      3\u001b[0m         \u001b[38;5;66;03m# Threshold the probabilities to get class predictions (0 or 1)\u001b[39;00m\n\u001b[0;32m      4\u001b[0m predicted_class \u001b[38;5;241m=\u001b[39m (probabilities \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0.5\u001b[39m)\u001b[38;5;241m.\u001b[39mint()\n\u001b[1;32m----> 6\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mProbabilities:\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[43mprobabilities\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mitem\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[0;32m      7\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPredicted class:\u001b[39m\u001b[38;5;124m\"\u001b[39m, predicted_class)\n",
            "\u001b[1;31mRuntimeError\u001b[0m: a Tensor with 2 elements cannot be converted to Scalar"
          ]
        }
      ],
      "source": [
        "probabilities = torch.sigmoid(prediction)\n",
        "        \n",
        "        # Threshold the probabilities to get class predictions (0 or 1)\n",
        "predicted_class = (probabilities > 0.5).int()\n",
        "\n",
        "print(\"Probabilities:\", probabilities.item())\n",
        "print(\"Predicted class:\", predicted_class)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [
        {
          "ename": "FileNotFoundError",
          "evalue": "[WinError 2] The system cannot find the file specified: 'neural_model.mar' -> 'model.mar'",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "Cell \u001b[1;32mIn[8], line 12\u001b[0m\n\u001b[0;32m      9\u001b[0m os\u001b[38;5;241m.\u001b[39msystem(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtorch-model-archiver --model-name neural_model --version 1.0 --serialized-file model.pt --handler classifier --extra-files loan_approval_preprocessor.joblib,label_encoders.joblib --export-path . --force\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     11\u001b[0m \u001b[38;5;66;03m# Optionally, rename the file to model.mar\u001b[39;00m\n\u001b[1;32m---> 12\u001b[0m \u001b[43mos\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrename\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mneural_model.mar\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmodel.mar\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
            "\u001b[1;31mFileNotFoundError\u001b[0m: [WinError 2] The system cannot find the file specified: 'neural_model.mar' -> 'model.mar'"
          ]
        }
      ],
      "source": [
        "# New cell: Save model as model.mar using TorchScript and torch-model-archiver\n",
        "import os\n",
        "\n",
        "# Convert the model to TorchScript\n",
        "scripted_model = torch.jit.script(model)\n",
        "scripted_model.save('model.pt')\n",
        "\n",
        "# Archive the model. Adjust --handler if you have a custom handler.\n",
        "os.system(\"torch-model-archiver --model-name neural_model --version 1.0 --serialized-file model.pt --handler classifier --extra-files loan_approval_preprocessor.joblib,label_encoders.joblib --export-path . --force\")\n",
        "\n",
        "# Optionally, rename the file to model.mar\n",
        "os.rename(\"neural_model.mar\", \"model.mar\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# New cell: Convert TorchScript model to GGUF format\n",
        "import os\n",
        "\n",
        "# Ensure that 'model.pt' has been created by previous TorchScript conversion.\n",
        "# Replace \"your-gguf-converter\" and arguments with the actual command if/when available.\n",
        "os.system(\"your-gguf-converter --input model.pt --output model.gguf\")"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
